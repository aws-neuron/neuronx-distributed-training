.. _nxdt_tutorials:

Tutorials
=========

This section will go over a bunch of tutorials to help users get started with NeuronxDistributedTraining library.

.. toctree::
    :maxdepth: 1

    Megatron GPT Pretraining <megatron_gpt_pretraining>
    HuggingFace Llama3-8B Pretraining <hf_llama3_8B_pretraining>
    HuggingFace Llama3-70B, Llama3.1-70B Pretraining <hf_llama3_70B_pretraining>
    HuggingFace Llama3-8B Supervised Fine-tuning <hf_llama3_8B_SFT>
    HuggingFace Llama3-8B Efficient Supervised Fine-tuning with LoRA <hf_llama3_8B_SFT_LORA>
    HuggingFace Llama3-8B Direct Preference Optimization (DPO) based Fine-tuning <hf_llama3_8B_DPO>
    Checkpoint Conversion <checkpoint_conversion>
